{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_x = np.load(\"pi_train_data_ann.npy\")\n",
    "pi_y = np.load(\"pi_train_label_ann.npy\")\n",
    "z_x = np.load(\"z_train_data_ann.npy\")\n",
    "z_y = np.load(\"z_train_label_ann.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1717, 1, 10, 1) (1717, 9) (1717, 1, 10, 1) (1717, 1)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(pi_x),np.shape(pi_y),np.shape(z_x),np.shape(z_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 2.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 2.]]] [ 0.  0.  0.  0.  0.  0.  0.  0.  0.] [[[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 2.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 2.]]] [-1.]\n"
     ]
    }
   ],
   "source": [
    "print pi_x[600],pi_y[600],z_x[600],z_y[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "\n",
    "\tp = y_pred\n",
    "\tpi = y_true\n",
    "\n",
    "\tzero = tf.zeros(shape = tf.shape(pi), dtype=tf.float32)\n",
    "\twhere = tf.equal(pi, zero)\n",
    "\n",
    "\tnegatives = tf.fill(tf.shape(pi), -100.0) \n",
    "\tp = tf.where(where, negatives, p)\n",
    "\n",
    "\tloss = tf.nn.softmax_cross_entropy_with_logits(labels = pi, logits = p)\n",
    "\n",
    "\treturn loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "from keras.layers import Dense, Activation, Conv2D, BatchNormalization, LeakyReLU, Flatten, merge, Input, ELU, concatenate\n",
    "from keras.models import load_model, Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(_in):\n",
    "\n",
    "\n",
    "    conv1 = Conv2D(256, (3, 3), activation='linear', kernel_regularizer = regularizers.l2(0.0001),padding = 'same')(_in)\n",
    "\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    lr1 = ELU()(bn1)\n",
    "\n",
    "    return lr1\n",
    "\n",
    "\n",
    "def residual_layer(_in):\n",
    "\n",
    "    conv1 = Conv2D(256, (3, 3), activation='linear', kernel_regularizer = regularizers.l2(0.0001),padding = 'same')(_in)\n",
    "\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    lr1 = ELU()(bn1)\n",
    "    \n",
    "    conv2 = Conv2D(256, (3, 3), activation='linear', kernel_regularizer = regularizers.l2(0.0001),padding = 'same')(lr1)\n",
    "\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    m1 = concatenate([_in, bn2])\n",
    "    \n",
    "    lr2 = ELU()(m1)\n",
    "    \n",
    "    \n",
    "    return lr2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def value_head(_in):\n",
    "\n",
    "\n",
    "    conv1 = Conv2D(1, (1, 1), activation='linear', kernel_regularizer = regularizers.l2(0.0001),padding = 'same')(_in)\n",
    "\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "\n",
    "    lr1 = ELU()(bn1)\n",
    "\n",
    "    f1 = Flatten()(lr1)\n",
    "\n",
    "    d1 = Dense(20, activation='linear', kernel_regularizer=regularizers.l2(0.0001))(f1)\n",
    "\n",
    "    lr2 = ELU()(d1)\n",
    "\n",
    "    d2 = Dense(1, use_bias=False, activation='tanh', kernel_regularizer=regularizers.l2(0.0001))(lr2)\n",
    "\n",
    "    return d2\n",
    "\n",
    "def policy_head(_in):\n",
    "\n",
    "\n",
    "    conv1 = Conv2D(2, (1, 1), activation='linear', kernel_regularizer = regularizers.l2(0.0001),padding = 'same')(_in)\n",
    "\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "\n",
    "    lr1 = ELU()(bn1)\n",
    "\n",
    "    f1 = Flatten()(lr1)\n",
    "\n",
    "    d1 = Dense(9, activation='linear', kernel_regularizer=regularizers.l2(0.0001))(f1)\n",
    "\n",
    "    return d1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_z():\n",
    "    inputs = Input(shape=(1, 10, 1))\n",
    "    \n",
    "    conv1 = conv_layer(inputs)\n",
    "    \n",
    "    r1 = residual_layer(conv1)\n",
    "    r2 = residual_layer(r1)\n",
    "    r3 = residual_layer(r2)\n",
    "    r4 = residual_layer(r3)\n",
    "    r5 = residual_layer(r4)\n",
    "    r6 = residual_layer(r5)\n",
    "    r7 = residual_layer(r6)\n",
    "    r8 = residual_layer(r7)\n",
    "    r9 = residual_layer(r8)\n",
    "    r10 = residual_layer(r9)\n",
    "\n",
    "    r11 = residual_layer(r10)\n",
    "    r12 = residual_layer(r11)\n",
    "    r13 = residual_layer(r12)\n",
    "    r14 = residual_layer(r13)\n",
    "    r15 = residual_layer(r14)\n",
    "    r16 = residual_layer(r15)\n",
    "    r17 = residual_layer(r16)\n",
    "    r18 = residual_layer(r17)\n",
    "    r19 = residual_layer(r18)\n",
    "    r20 = residual_layer(r19)\n",
    "\n",
    "    r21 = residual_layer(r20)\n",
    "    r22 = residual_layer(r21)\n",
    "    r23 = residual_layer(r22)\n",
    "    r24 = residual_layer(r23)\n",
    "    r25 = residual_layer(r24)\n",
    "    r26 = residual_layer(r25)\n",
    "    r27 = residual_layer(r26)\n",
    "    r28 = residual_layer(r27)\n",
    "    r29 = residual_layer(r28)\n",
    "    r30 = residual_layer(r29)\n",
    "\n",
    "\n",
    "    r31 = residual_layer(r30)\n",
    "    r32 = residual_layer(r31)\n",
    "    r33 = residual_layer(r32)\n",
    "    r34 = residual_layer(r33)\n",
    "    r35 = residual_layer(r34)\n",
    "    r36 = residual_layer(r35)\n",
    "    r37 = residual_layer(r36)\n",
    "    r38 = residual_layer(r37)\n",
    "    r39 = residual_layer(r38)\n",
    "    r40 = residual_layer(r39)\n",
    "\n",
    "    output = value_head(r40)\n",
    "\n",
    "\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1, momentum = 0.9))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pi():\n",
    "    inputs = Input(shape=(1, 10, 1))\n",
    "    \n",
    "    conv1 = conv_layer(inputs)\n",
    "    \n",
    "    r1 = residual_layer(conv1)\n",
    "    r2 = residual_layer(r1)\n",
    "    r3 = residual_layer(r2)\n",
    "    r4 = residual_layer(r3)\n",
    "    r5 = residual_layer(r4)\n",
    "    r6 = residual_layer(r5)\n",
    "    r7 = residual_layer(r6)\n",
    "    r8 = residual_layer(r7)\n",
    "    r9 = residual_layer(r8)\n",
    "    r10 = residual_layer(r9)\n",
    "\n",
    "    r11 = residual_layer(r10)\n",
    "    r12 = residual_layer(r11)\n",
    "    r13 = residual_layer(r12)\n",
    "    r14 = residual_layer(r13)\n",
    "    r15 = residual_layer(r14)\n",
    "    r16 = residual_layer(r15)\n",
    "    r17 = residual_layer(r16)\n",
    "    r18 = residual_layer(r17)\n",
    "    r19 = residual_layer(r18)\n",
    "    r20 = residual_layer(r19)\n",
    "\n",
    "    r21 = residual_layer(r20)\n",
    "    r22 = residual_layer(r21)\n",
    "    r23 = residual_layer(r22)\n",
    "    r24 = residual_layer(r23)\n",
    "    r25 = residual_layer(r24)\n",
    "    r26 = residual_layer(r25)\n",
    "    r27 = residual_layer(r26)\n",
    "    r28 = residual_layer(r27)\n",
    "    r29 = residual_layer(r28)\n",
    "    r30 = residual_layer(r29)\n",
    "\n",
    "\n",
    "    r31 = residual_layer(r30)\n",
    "    r32 = residual_layer(r31)\n",
    "    r33 = residual_layer(r32)\n",
    "    r34 = residual_layer(r33)\n",
    "    r35 = residual_layer(r34)\n",
    "    r36 = residual_layer(r35)\n",
    "    r37 = residual_layer(r36)\n",
    "    r38 = residual_layer(r37)\n",
    "    r39 = residual_layer(r38)\n",
    "    r40 = residual_layer(r39)\n",
    "\n",
    "    output = policy_head(r40)\n",
    "\n",
    "\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    model.compile(loss=custom_loss_function, optimizer=SGD(lr=0.1, momentum = 0.9))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_x = np.load(\"pi_train_data_ann.npy\")\n",
    "pi_y = np.load(\"pi_train_label_ann.npy\")\n",
    "\n",
    "dis = np.random.choice(np.shape(pi_x)[0], 20, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 688  214 1231  367 1359 1035  703  427 1427  864 1343  481  342  492 1384\n",
      " 1616 1507  708 1688  265]\n"
     ]
    }
   ],
   "source": [
    "print dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-0ee65022041f>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2962s 6s/step - loss: 5.6970\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3098s 6s/step - loss: 4.9504\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2854s 6s/step - loss: 4.2903\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3054s 6s/step - loss: 3.8005\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2918s 6s/step - loss: 3.3597\n",
      "Epoch 1/1\n",
      "  1/512 [..............................] - ETA: 53:32 - loss: 3.8742"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b0c3c0a7b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pi_model_ann.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pi_x = np.load(\"pi_train_data_ann.npy\")\n",
    "pi_y = np.load(\"pi_train_label_ann.npy\")\n",
    "\n",
    "\n",
    "if  os.path.isfile(\"pi_model_ann.h5\"):\n",
    "        \n",
    "    pi = load_model('pi_model_ann.h5', custom_objects={'custom_loss_function': custom_loss_function})\n",
    "else:\n",
    "    pi = model_pi()\n",
    "\n",
    "\n",
    "for i in range(3000):\n",
    "    \n",
    "    dis = np.random.choice(np.shape(pi_x)[0], 512, replace=False)\n",
    "    \n",
    "\n",
    "    pi.fit(pi_x[dis], pi_y[dis], epochs=1, batch_size= 1)\n",
    "    \n",
    "pi.save(\"pi_model_ann.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2970s 6s/step - loss: 50.0887\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3069s 6s/step - loss: 42.3075\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2831s 6s/step - loss: 34.7771\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2832s 6s/step - loss: 28.5512\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2833s 6s/step - loss: 23.5166\n"
     ]
    }
   ],
   "source": [
    "z_x = np.load(\"z_train_data_ann.npy\")\n",
    "z_y = np.load(\"z_train_label_ann.npy\")\n",
    "\n",
    "if  os.path.isfile(\"z_model_ann.h5\"):\n",
    "        \n",
    "    z = load_model(\"z_model_ann.h5\")\n",
    "else:\n",
    "    z = model_z()\n",
    "\n",
    "\n",
    "for i in range(3000):\n",
    "    \n",
    "    dis = np.random.choice(np.shape(z_x)[0], 512, replace=False)\n",
    "    \n",
    "\n",
    "    z.fit(z_x[dis], z_y[dis], epochs=1, batch_size= 1)\n",
    "    \n",
    "z.save(\"z_model_ann.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
